{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  age  sex  survived\n",
       "0      1    1    1         1\n",
       "1      1    1    1         1\n",
       "2      1    1    1         1\n",
       "3      1    1    1         1\n",
       "4      1    1    1         1"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/gsprint23/cpts215/master/progassignments/files/titanic.txt')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "       False])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['class','age','sex']\n",
    "df['survived'] = df['survived'].apply(lambda x: False if x==0 else True)\n",
    "X = df.loc[:,cols].values\n",
    "y = df['survived'].ravel()\n",
    "y[50:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ID3():\n",
    "    \n",
    "    def __init__(self,col_names):\n",
    "        '''\n",
    "        col_names: column names of attributes\n",
    "        '''\n",
    "        self.col_names = col_names\n",
    "    \n",
    "    \n",
    "    def transform_structure(self,X,y=None):\n",
    "        '''\n",
    "        This will change the data type from X,y arrays to a list of dictonaries format\n",
    "        '''\n",
    "        lis_dic = []\n",
    "        for i in range(len(X)):\n",
    "            dic = {}\n",
    "            for j in range(len(X[i])):\n",
    "                dic[self.col_names[j]] = X[i][j]\n",
    "            if y is not None:\n",
    "                lis_dic.append((dic,y[i]))\n",
    "            else:\n",
    "                lis_dic.append(dic)\n",
    "        return lis_dic\n",
    "\n",
    "\n",
    "    def compute_entropy(self,class_probabilities):\n",
    "        '''\n",
    "        class_probabilities is a list of class probabilities\n",
    "        '''\n",
    "        terms = [-pi * np.log2(pi) for pi in class_probabilities if pi] # ignore zero probabilities\n",
    "        H = np.sum(terms)\n",
    "        return H\n",
    "\n",
    "\n",
    "    def compute_class_probabilities(self,instance_labels):\n",
    "        '''\n",
    "        instance_labels is a list of each examples' class label\n",
    "        '''\n",
    "        num_examples = len(instance_labels)\n",
    "        counts = list(Counter(instance_labels).values())\n",
    "        probabilities = np.array(counts) / num_examples\n",
    "        return probabilities\n",
    "\n",
    "\n",
    "    def compute_subset_entropy(self,subset):\n",
    "        '''\n",
    "        subset is a list of instances as two-item tuples (attributes, label)\n",
    "        '''\n",
    "        labels = [label for _, label in subset]\n",
    "        probabilities = self.compute_class_probabilities(labels)\n",
    "        entropy = self.compute_entropy(probabilities)\n",
    "        return entropy\n",
    "\n",
    "\n",
    "    def compute_partition_entropy(self,subsets):\n",
    "        '''\n",
    "        subsets is a list of class label lists\n",
    "        '''\n",
    "        num_examples = np.sum([len(s) for s in subsets])\n",
    "        entropies = [(len(s) / num_examples) * self.compute_subset_entropy(s) for s in subsets]\n",
    "        partition_entropy = np.sum(entropies)\n",
    "        return partition_entropy\n",
    "\n",
    "\n",
    "    def partition_by(self,inputs, attribute):\n",
    "        '''\n",
    "        inputs is a list of tuple pairs: (attribute_dict, label)\n",
    "        attribute is the proposed attribute to partition by\n",
    "        returns a dictionary of attribute value: input subsets pairs\n",
    "        '''\n",
    "        subsets = {}\n",
    "        for example in inputs:\n",
    "            attribute_value = example[0][attribute]\n",
    "            if attribute_value in subsets:\n",
    "                subsets[attribute_value].append(example)\n",
    "            else: # add this attribute_value to the dict\n",
    "                subsets[attribute_value] = [example]\n",
    "        return subsets\n",
    "\n",
    "    \n",
    "    def partition_entropy_by(self,inputs, attribute):\n",
    "        '''\n",
    "        compute the partition\n",
    "        compute the entropy of the partition\n",
    "        '''\n",
    "        subsets = self.partition_by(inputs, attribute)\n",
    "        entropies = self.compute_partition_entropy(subsets.values())\n",
    "        return entropies\n",
    "\n",
    "\n",
    "    def find_min_entropy_partition(self,inputs, attributes=None):\n",
    "        '''\n",
    "\n",
    "        '''\n",
    "        if attributes is None:\n",
    "            attributes = list(inputs[0][0].keys())\n",
    "        partition_entropies = []\n",
    "        for attribute in attributes:\n",
    "            partition_entropy = self.partition_entropy_by(inputs, attribute)\n",
    "            # print(attribute, partition_entropy)\n",
    "            partition_entropies.append(partition_entropy)\n",
    "        min_index = np.argmin(partition_entropies)\n",
    "        return attributes[min_index]\n",
    "\n",
    "    \n",
    "    def build_tree(self,inputs, split_candidates=None):\n",
    "        '''\n",
    "        implements the ID3 algorithm to build a decision tree\n",
    "        '''\n",
    "        if split_candidates is None:\n",
    "            # this is the first pass\n",
    "            split_candidates = list(inputs[0][0].keys())\n",
    "\n",
    "        num_examples = len(inputs)\n",
    "        # count Trues and Falses in the examples\n",
    "        num_trues = len([label for attributes, label in inputs if label == True])\n",
    "        num_falses = num_examples - num_trues\n",
    "\n",
    "        # part (1) in the ID3 algorithm -> all same class label\n",
    "        if num_trues == 0: # no trues, this is a False leaf node\n",
    "            return False\n",
    "        if num_falses == 0: # no falses, this is a True leaf node\n",
    "            return True\n",
    "\n",
    "        # part (2) in the ID3 algorithm -> list of attributes is empty -> leaf node with majority class label\n",
    "        if not split_candidates: \n",
    "            return num_trues >= num_falses\n",
    "\n",
    "        # part (3) in ID3 algorithm -> split on best attribute\n",
    "        split_attribute = self.find_min_entropy_partition(inputs, split_candidates)\n",
    "        partitions = self.partition_by(inputs, split_attribute)\n",
    "        new_split_candidates = split_candidates[:]\n",
    "        new_split_candidates.remove(split_attribute)\n",
    "\n",
    "        # recursively build the subtrees\n",
    "        subtrees = {}\n",
    "        for attribute_value, subset in partitions.items():\n",
    "            subtrees[attribute_value] = self.build_tree(subset, new_split_candidates)\n",
    "\n",
    "        # missing (or unexpected) attribute value\n",
    "        subtrees[None] = num_trues > num_falses\n",
    "\n",
    "        return (split_attribute, subtrees)\n",
    "\n",
    "    \n",
    "    def fit(self,X,y):\n",
    "        self.tree = self.build_tree(self.transform_structure(X,y))\n",
    "        \n",
    "        \n",
    "    def classify(self,tree,new_example):\n",
    "        '''\n",
    "        classify new_example using decision tree\n",
    "        '''\n",
    "        # leaf node, return value\n",
    "        if tree in [True, False]:\n",
    "            return tree\n",
    "\n",
    "        # decision node, unpack the attribute to split on and subtrees\n",
    "        attribute, subtree_dict = tree\n",
    "\n",
    "        subtree_key = new_example.get(attribute) # get return None if attribute not in new_example dict\n",
    "        if subtree_key not in subtree_dict:\n",
    "            subtree_key = None # use None subtree if no subtree for key\n",
    "\n",
    "        subtree = subtree_dict[subtree_key]\n",
    "        label = self.classify(subtree, new_example)\n",
    "        return label\n",
    "    \n",
    "  \n",
    "    def predict(self,X):\n",
    "        '''\n",
    "        Predict on the training instances\n",
    "        '''\n",
    "        X = self.transform_structure(X)\n",
    "        return [(self.classify(self.tree,i)) for i in X]\n",
    "    \n",
    "    \n",
    "    def get_params(self, deep = False):\n",
    "        return {'col_names':self.col_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.06531596, 0.04199862, 0.0233717 , 0.02322888, 0.02225065]),\n",
       " 'score_time': array([0.01384068, 0.00596166, 0.00660777, 0.00558376, 0.00540304]),\n",
       " 'test_accuracy': array([0.8185941 , 0.775     , 0.66818182, 0.575     , 0.99318182]),\n",
       " 'test_precision': array([0.97241379, 0.87735849, 0.42213115, 0.        , 0.86956522]),\n",
       " 'test_recall': array([0.64976959, 0.51955307, 0.9537037 , 0.        , 1.        ]),\n",
       " 'test_f1': array([0.77900552, 0.65263158, 0.58522727, 0.        , 0.93023256])}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score,cross_validate\n",
    "cross_validate(ID3(cols),X,y,cv=5,scoring=['accuracy','precision','recall','f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_format(df,label='survived'):\n",
    "    df_dict = df.to_dict('records')\n",
    "    updated_format = []  \n",
    "    for row in df_dict:\n",
    "        label_val = row.pop(label)\n",
    "        if label_val == 1:\n",
    "            label_val = True\n",
    "        else:\n",
    "            label_val = False\n",
    "            \n",
    "        updated_row = (row,label_val)\n",
    "        updated_format.append(updated_row)\n",
    "    return updated_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ID3():\n",
    "    \n",
    "    def __init__(self,col_names):\n",
    "        '''\n",
    "        col_names: column names of attributes\n",
    "        '''\n",
    "        self.col_names = col_names\n",
    "    \n",
    "    \n",
    "    def transform_structure(self,X,y=None):\n",
    "        '''\n",
    "        This will change the data type from X,y arrays to a list of dictonaries format\n",
    "        '''\n",
    "        lis_dic = []\n",
    "        for i in range(len(X)):\n",
    "            dic = {}\n",
    "            for j in range(len(X[i])):\n",
    "                dic[self.col_names[j]] = X[i][j]\n",
    "            if y is not None:\n",
    "                lis_dic.append((dic,y[i]))\n",
    "            else:\n",
    "                lis_dic.append(dic)\n",
    "        return lis_dic\n",
    "\n",
    "\n",
    "    def compute_entropy(self,class_probabilities):\n",
    "        '''\n",
    "        class_probabilities is a list of class probabilities\n",
    "        '''\n",
    "        terms = [-pi * np.log2(pi) for pi in class_probabilities if pi] # ignore zero probabilities\n",
    "        H = np.sum(terms)\n",
    "        return H\n",
    "\n",
    "\n",
    "    def compute_class_probabilities(self,instance_labels):\n",
    "        '''\n",
    "        instance_labels is a list of each examples' class label\n",
    "        '''\n",
    "        num_examples = len(instance_labels)\n",
    "        counts = list(Counter(instance_labels).values())\n",
    "        probabilities = np.array(counts) / num_examples\n",
    "        return probabilities\n",
    "\n",
    "\n",
    "    def compute_subset_entropy(self,subset):\n",
    "        '''\n",
    "        subset is a list of instances as two-item tuples (attributes, label)\n",
    "        '''\n",
    "        labels = [label for _, label in subset]\n",
    "        probabilities = self.compute_class_probabilities(labels)\n",
    "        entropy = self.compute_entropy(probabilities)\n",
    "        return entropy\n",
    "\n",
    "\n",
    "    def compute_partition_entropy(self,subsets):\n",
    "        '''\n",
    "        subsets is a list of class label lists\n",
    "        '''\n",
    "        num_examples = np.sum([len(s) for s in subsets])\n",
    "        entropies = [(len(s) / num_examples) * self.compute_subset_entropy(s) for s in subsets]\n",
    "        partition_entropy = np.sum(entropies)\n",
    "        return partition_entropy\n",
    "\n",
    "\n",
    "    def partition_by(self,inputs, attribute):\n",
    "        '''\n",
    "        inputs is a list of tuple pairs: (attribute_dict, label)\n",
    "        attribute is the proposed attribute to partition by\n",
    "        returns a dictionary of attribute value: input subsets pairs\n",
    "        '''\n",
    "        subsets = {}\n",
    "        for example in inputs:\n",
    "            attribute_value = example[0][attribute]\n",
    "            if attribute_value in subsets:\n",
    "                subsets[attribute_value].append(example)\n",
    "            else: # add this attribute_value to the dict\n",
    "                subsets[attribute_value] = [example]\n",
    "        return subsets\n",
    "\n",
    "    \n",
    "    def partition_entropy_by(self,inputs, attribute):\n",
    "        '''\n",
    "        compute the partition\n",
    "        compute the entropy of the partition\n",
    "        '''\n",
    "        subsets = self.partition_by(inputs, attribute)\n",
    "        entropies = self.compute_partition_entropy(subsets.values())\n",
    "        return entropies\n",
    "\n",
    "\n",
    "    def find_min_entropy_partition(self,inputs, attributes=None):\n",
    "        '''\n",
    "\n",
    "        '''\n",
    "        if attributes is None:\n",
    "            attributes = list(inputs[0][0].keys())\n",
    "        partition_entropies = []\n",
    "        for attribute in attributes:\n",
    "            partition_entropy = self.partition_entropy_by(inputs, attribute)\n",
    "            # print(attribute, partition_entropy)\n",
    "            partition_entropies.append(partition_entropy)\n",
    "        min_index = np.argmin(partition_entropies)\n",
    "        return attributes[min_index]\n",
    "\n",
    "    \n",
    "    def build_tree(self,inputs, split_candidates=None):\n",
    "        '''\n",
    "        implements the ID3 algorithm to build a decision tree\n",
    "        '''\n",
    "        if split_candidates is None:\n",
    "            # this is the first pass\n",
    "            split_candidates = list(inputs[0][0].keys())\n",
    "\n",
    "        num_examples = len(inputs)\n",
    "        # count Trues and Falses in the examples\n",
    "        num_trues = len([label for attributes, label in inputs if label == True])\n",
    "        num_falses = num_examples - num_trues\n",
    "\n",
    "        # part (1) in the ID3 algorithm -> all same class label\n",
    "        if num_trues == 0: # no trues, this is a False leaf node\n",
    "            return False\n",
    "        if num_falses == 0: # no falses, this is a True leaf node\n",
    "            return True\n",
    "\n",
    "        # part (2) in the ID3 algorithm -> list of attributes is empty -> leaf node with majority class label\n",
    "        if not split_candidates: \n",
    "            return num_trues >= num_falses\n",
    "\n",
    "        # part (3) in ID3 algorithm -> split on best attribute\n",
    "        split_attribute = self.find_min_entropy_partition(inputs, split_candidates)\n",
    "        partitions = self.partition_by(inputs, split_attribute)\n",
    "        new_split_candidates = split_candidates[:]\n",
    "        new_split_candidates.remove(split_attribute)\n",
    "\n",
    "        # recursively build the subtrees\n",
    "        subtrees = {}\n",
    "        for attribute_value, subset in partitions.items():\n",
    "            subtrees[attribute_value] = self.build_tree(subset, new_split_candidates)\n",
    "\n",
    "        # missing (or unexpected) attribute value\n",
    "        subtrees[None] = num_trues > num_falses\n",
    "\n",
    "        return (split_attribute, subtrees)\n",
    "\n",
    "\n",
    "    def classify(self,tree, new_example):\n",
    "        '''\n",
    "        classify new_example using decision tree\n",
    "        '''\n",
    "        # leaf node, return value\n",
    "        if tree in [True, False]:\n",
    "            return tree\n",
    "\n",
    "        # decision node, unpack the attribute to split on and subtrees\n",
    "        attribute, subtree_dict = tree\n",
    "\n",
    "        subtree_key = new_example.get(attribute) # get return None if attribute not in new_example dict\n",
    "        if subtree_key not in subtree_dict:\n",
    "            subtree_key = None # use None subtree if no subtree for key\n",
    "\n",
    "        subtree = subtree_dict[subtree_key]\n",
    "        label = self.classify(subtree, new_example)\n",
    "        return label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def predict(X):\n",
    "    '''\n",
    "    Predict on the training instances\n",
    "    '''\n",
    "    instances = [id3.transform_structure(x) for x in X]\n",
    "    return [self.classify(tree,instance) for instance in instances]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True, False]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id3 = ID3(col_names=cols)\n",
    "X = np.array([[1,2,3],[4,5,6]])\n",
    "y=[True,False]\n",
    "\n",
    "id3.fit(X,y)\n",
    "\n",
    "single_X_test_element = id3.transform_structure(X)[1]\n",
    "print(id3.classify(id3.tree,single_X_test_element))\n",
    "\n",
    "id3.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.00019526, 0.00015473]),\n",
       " 'score_time': array([0.00764656, 0.00361347]),\n",
       " 'test_accuracy': array([0., 0.]),\n",
       " 'test_precision': array([0., 0.]),\n",
       " 'test_recall': array([0., 0.]),\n",
       " 'test_f1': array([0., 0.])}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score,cross_validate\n",
    "cross_validate(id3,X,y,cv=2,scoring=['accuracy','precision','recall','f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        True\n",
       "1        True\n",
       "2        True\n",
       "3        True\n",
       "4        True\n",
       "        ...  \n",
       "2196     True\n",
       "2197     True\n",
       "2198    False\n",
       "2199    False\n",
       "2200    False\n",
       "Name: survived, Length: 2201, dtype: bool"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git init\n",
    "! git add -A\n",
    "! git commit -m \"start of e\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
